{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ce39f8-54e1-46e1-a529-9975bedd08fa",
   "metadata": {},
   "source": [
    "## This code reads one at a time .dat files generated after running the PANDAT simulations using panpython. It can read large number of files as it runs in parallel and post process it based on the information required. The data is stored in a pickle format as large number of rows and columns cannot be accomodated in excel. This code can also plot the Cp, density and phase diagram for the given dataframe obtained after filtering the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebdafd-d8fd-49e2-bd89-3ccd9f1eac40",
   "metadata": {},
   "source": [
    "### Importing all the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45c2f7-ba89-488b-8b19-abfaf6116e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "#Define the path where files are placed\n",
    "files_path = glob.glob(\"output/intermediate/*.dat\")\n",
    "print(f'Total number of dat files are {len(files_path)}')\n",
    "#files_path = files_path[0:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45359c9-3ce9-4bf1-835b-b8b8ffbca95b",
   "metadata": {},
   "source": [
    "### Defining a function to read all the dat files and processing it on the go and extratcing the required information form a given .dat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326c5bc-f815-4e82-a066-ad3b886e832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat_file_post_process(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    df = df.drop([0, len(df)-1])\n",
    "    \n",
    "    df = df.rename(columns={'T': 'Temp'})\n",
    "    \n",
    "    # Select columns that start with \"f(@\" using startswith() method\n",
    "    all_phases_columns = [col for col in df.columns if col.startswith('f(@')]\n",
    "    # Select columns that start with \"f(@B)\"\n",
    "    required_cols = [col for col in all_phases_columns if col.startswith('f(@B')]\n",
    "    # Exclude columns that start with \"f(@B\" using list comprehension\n",
    "    not_required_cols = [col for col in all_phases_columns if not col.startswith('f(@B')]\n",
    "    \n",
    "    #putting the required mask\n",
    "    #This mask is for getting the temperature for the onset of BCC or B2 phase with no other phase present and solidus temp\n",
    "    mask_temp = df[required_cols].notna().all(axis=1) & df[not_required_cols].isna().all(axis=1)\n",
    "    onset_of_B_phase = df.loc[mask_temp, 'Temp'].astype(float).min()\n",
    "    solidus = df.loc[mask_temp, 'Temp'].astype(float).max()\n",
    "    range_of_single_phase = solidus - onset_of_B_phase\n",
    "    \n",
    "    #Max and min Cp and densities\n",
    "    max_cp = df['Cp'].astype(float).max()\n",
    "    min_cp = df['Cp'].astype(float).min()\n",
    "    \n",
    "    max_den = df['density'].astype(float).max()\n",
    "    min_den = df['density'].astype(float).min()\n",
    "    \n",
    "    #Getting the composition and it value and making a dataframe\n",
    "    comp_columns = [col for col in df.columns if col.startswith('x(')]\n",
    "    comp = df.loc[2, comp_columns]\n",
    "    comp_df = pd.DataFrame(comp).transpose()\n",
    "    comp_df = comp_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # combining all the necessary value to one dataframe alsong with the filename\n",
    "    final_df = pd.DataFrame({'onset of single phase': onset_of_B_phase, 'Solidus': solidus, 'range of single phase': range_of_single_phase,\n",
    "                             'max cp': max_cp, 'min Cp': min_cp,'max density': max_den, \n",
    "                             'min density': min_den, 'filename': str(file_path) }, index=[0])\n",
    "    \n",
    "    # concatenating the dataframes\n",
    "    result_df = pd.concat([comp_df, final_df], axis=1)\n",
    "    float_cols = result_df.select_dtypes(include=['float']).columns\n",
    "    result_df[float_cols] = result_df[float_cols].round(2)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8755a-13ac-4f07-9282-0728254f19b2",
   "metadata": {},
   "source": [
    "## Reading the files, processing it and storing it a dataframe as a picke format. Pickle format file can be read later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a1fbc-55f6-42a0-8744-10b628a0e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = time.time()\n",
    "def process_file(file_path):\n",
    "    result = read_dat_file_post_process(file_path)\n",
    "    return result\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 4) as executor:\n",
    "    # submit the function to the pool for each file path\n",
    "    futures = [executor.submit(process_file, file_path) for file_path in files_path]\n",
    "    \n",
    "    # combine the results from each process\n",
    "    result = pd.concat([f.result() for f in futures])\n",
    "\n",
    "    # Write dataframe to pickle file\n",
    "with open('final_processed_data.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f)\n",
    "    \n",
    "fin = time.time()\n",
    "total_time = round((fin-ini)/60,2)\n",
    "print(f'Total time taken to read and process {len(files_path)} files is {total_time} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d937ce-ecb7-41d4-b4cd-44022d12457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viweing the dataframe\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119cabd-4452-4ec3-be3b-435ced5055cf",
   "metadata": {},
   "source": [
    "### Getting the total memory of the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a264e7-1d0d-447c-a1a2-ebcadccffb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = []\n",
    "a = result.memory_usage(deep = True)\n",
    "for i in range(len(a)):\n",
    "    _ = a[i]\n",
    "    memory.append(_)\n",
    "ar = np.array(memory)\n",
    "ar = round((ar.sum()/1073741824),2)\n",
    "print(f'Size of dataframe is {ar} GB')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6931d77-0288-433a-a091-5075e67975cb",
   "metadata": {},
   "source": [
    "#Template for reading the pickle file\n",
    "\n",
    "ini = time.time()\n",
    "# Read dataframe from pickle file\n",
    "with open('final_processed_data.pickle', 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "fin = time.time()\n",
    "print(fin-ini)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7862a9-41c4-4b83-8133-7e7b18969d2f",
   "metadata": {},
   "source": [
    "## Sorting/filtering the dataframe as per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de5235-8d2e-4379-bb63-a4e32fb7d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30 = result.sort_values(by=['range of single phase'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0462e4-3b0a-4d6d-8c26-216139317705",
   "metadata": {},
   "source": [
    "## Plotting the phase diagram, Cp and density for the sorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87f6a1-2f5d-4e72-9a78-7ff353058662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib widget\n",
    "def ploting_phase_Cp_density_plots(filename):\n",
    "\n",
    "    #Collecting all the data for plotting\n",
    "    data = pd.read_csv(filename, sep = '\\t')\n",
    "    data = data.drop(index = 0)\n",
    "    phases_columns = [col for col in data.columns if col.startswith('f(@')]\n",
    "    density = data['density'].astype(float)\n",
    "    Cp = data['Cp'].astype(float)\n",
    "    Temp = data['T'].astype(float)\n",
    "\n",
    "    comp_columns = [col for col in data.columns if col.startswith('x(')]\n",
    "    comp_name = []\n",
    "    for col in comp_columns:\n",
    "        _ = col\n",
    "        comp_name.append(_)\n",
    "        __ = data.loc[1,col]\n",
    "        comp_name.append(__)\n",
    "\n",
    "\n",
    "    fig,axs = plt.subplots(nrows = 1, ncols = 3, figsize = (13,5))\n",
    "\n",
    "    #Plotting phase diagram\n",
    "    for col in phases_columns:\n",
    "        axs[0].plot(Temp, data[col], '-', label = col)\n",
    "\n",
    "    #Plotting density and Cp\n",
    "    axs[1].plot(Temp, density, label = 'Density' )\n",
    "    axs[2].plot(Temp, Cp, label = 'Cp' )\n",
    "\n",
    "    for i in range(3):\n",
    "        axs[i].set_xlabel('Temp (C)')\n",
    "        axs[i].legend()\n",
    "        axs[i].grid()\n",
    "        axs[i].set_title(str(comp_name))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(comp_name) + '.jpeg')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554f82a-c610-4924-802b-e0a1e49d08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in top_30['filename']:\n",
    "    ploting_phase_Cp_density_plots(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63040cc-2f6a-4b16-af5a-66b3b5aa7654",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
